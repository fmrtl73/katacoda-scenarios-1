In this step, we will take a snapshot of our Kafka volumes and show how it can be recovered from the snapshot.

### Step: Take snapshot using kubectl

We're going to use STORK to take a group snapshot of our Kafka cluster. Take a look at the px-snap.yaml file ```cat px-snap.yaml ```{{execute T1}} and notice that we defined the volume group name (kafka_vg) so Portworx will synchronously quiesce I/O on all volumes before triggering their snapshots. Let's take the snapshot:
```
kubectl create -f px-snap.yaml
```{{execute T1}}

You can see the snapshots using the following command:
```
kubectl get volumesnapshot,volumesnapshotdatas
```{{execute T1}}

Now we're going to go ahead and do something stupid because it's Katacoda and we're here to learn.

```
kubectl exec -it kafka-cli bash
./bin/kafka-topics.sh --zookeeper zk-headless:2181 --delete --topic test
./bin/kafka-topics.sh --zookeeper zk-headless:2181 --list
exit
```{{execute T1}}

Ok, so we deleted our topic, what now? Restore your snapshot and cary on.

### Step: Scale down cluster to restore the snapshot

Snapshots are just like volumes so we can go ahead and use it to start a new instance of Kafka.

First, lets scale down our Kafka cluster:
```
kubectl scale sts kafka --replicas=0
```{{execute T1}}

Make sure you wait for all three kafka pods to be deleted:
```
watch kubectl get pods
```{{execute T1}}

When all three kafka-* pods have been deleted hit ```clear```{{execute interrupt}} to ctrl-c and clear the screen move to the next step.
