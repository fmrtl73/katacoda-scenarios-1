In this step, we will restore the cloud snapshot of our Minio volume and launch a second Minio server with the recovered data.

### Step: Restore the cloud snapshot to a new volume

First, lets get the Snap ID
```
PX_POD=$(kubectl get pods -l name=portworx -n kube-system -o jsonpath='{.items[0].metadata.name}')
SNAP_ID=$(kubectl exec -it $PX_POD -n kube-system -- /opt/pwx/bin/pxctl cloudsnap list --cr 5fc25703-fa82-451d-ab63-f60fe45650d0 | grep -v VOLUME | awk '{print $3}')
```{{execute T1}}

Run this command to restore the backup
```
kubectl exec -it $PX_POD -n kube-system -- /opt/pwx/bin/pxctl cloudsnap restore -v minio-restored -s $SNAP_ID
```{{execute T1}}

Verify that the volume restore is completed (use shorthand for cloudsnap list - c l, and volume list - v l)
```
kubectl exec -it $PX_POD -n kube-system -- /opt/pwx/bin/pxctl cs l
kubectl exec -it $PX_POD -n kube-system -- /opt/pwx/bin/pxctl v l
```{{execute T1}}

### Step: Create a new PVC from the Cloud Snapshot and use it to start a new Minio server
Create a PVC and Deploy Minio with it by setting persistence.existingClaim on the helm chart.
```
kubectl create -f px-snap-pvc.yaml
helm install --name px-snap \
    --set accessKey=myaccesskey \
    --set secretKey=mysecretkey \
    --set persistence.existingClaim=minio-snap-clone \
    stable/minio
```{{execute T1}}

Run the below command and wait for the Minio pod to be in ready state.
```
watch kubectl get pods -o wide
```{{execute T1}}

When the Minio pod is in Running and Ready 1/1 state then hit ```clear```{{execute interrupt}} to ctrl-c and clear the screen.

### Step: Verify that Minio has our data
Set the endpoint to the px-snap minio svc
```
MINIO_ENDPOINT=$(kubectl describe svc px-snap-minio | grep Endpoints | awk '{print $2}')
mc config host add px http://$MINIO_ENDPOINT myaccesskey mysecretkey S3v4
```{{execute T1}}
List the contents of our bucket
```
mc ls px/yaml
```{{execute T1}}
