In this section we will create an ES cluster with

* 3 master nodes using a Kubernetes Deployment
* 3 data nodes using a Kubernetes Statefulset backed by Portworx volumes
* 2 client node using a Kubernetes Deployment

All pods will use the stork scheduler to enable them to be placed closer to where their data is located.

### Step: Create Elastic Search Master Nodes

First we will create a [Service](https://kubernetes.io/docs/concepts/services-networking/service/) and [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) for our 3 master nodes using the following yaml: ```cat es-master.yaml```{{execute T1}}. Note that we are configuring STORK as the scheduler to improve pod placement. Create the service and deployment:
```
kubectl create -f es-master.yaml
```{{execute T1}}
Now watch as the pods for the master initialize:
```
watch kubectl get pods
```{{execute T1}}

When the pod is in Running state then then hit ```clear```{{execute interrupt}} to ctrl-c and clear the screen. You can verify that the master nodes have create and joined the cluster by looking at the logs.
```
POD=`kubectl get pod | grep es-master | awk '{print $1}'`
kubectl logs $POD
```{{execute T1}}

### Step: Create Elastic Search Client

The Elastic Search client will also be deployed using a Service and Deployment, this time with 2 replicas. Take a look at the YAML: ```cat es-master.yaml```{{execute T1}} and deploy using kubectl:
```
kubectl create -f es-master.yaml
```{{execute T1}}
Now watch as the pods for the master initialize:
```
watch kubectl get pods
```{{execute T1}}

When the pod is in Running state then then hit ```clear```{{execute interrupt}} to ctrl-c and clear the screen. You can verify that the master nodes have create and joined the cluster by looking at the logs.
```
POD=`kubectl get pod | grep es-client | awk '{print $1}'`
kubectl logs $POD
```{{execute T1}}
