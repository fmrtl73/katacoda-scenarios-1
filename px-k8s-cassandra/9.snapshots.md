In this step, we will take a snapshot, simulate destroy our database, and recover from the snapshot

### Step: Take snapshot using kubectl

We're going to use STORK to take a 3DSnapshot of our Cassandra cluster. Take a look at the px-snap.yaml file ```cat px-snap.yaml ```{{execute T1}} and notice that we are going to force a ```nodetool flush``` command on each cluster member before we take the snapshot. As explained before, that will force all data to be written to disk. We also defined the volume group name so Portworx will quiesce I/O on all volumes before triggering their snapshots.

First let's insert a new record in our features table:
```
kubectl exec -it cqlsh -- cqlsh cassandra-0.cassandra.default.svc.cluster.local --cqlversion=3.4.4
INSERT INTO portworx.features (id, name, value) VALUES ('px-6', '3DSnaps', 'Application/Cluster aware snapshots!');
quit
```{{execute T1}}

Now let's take a snapshot.
```
kubectl create -f px-snap.yaml
```{{execute T1}}

You can see the snapshots using the following command:
```
kubectl get volumesnapshot,volumesnapshotdatas
```{{execute T1}}

Now we're going to go ahead and do something stupid because it's Katacoda and we're here to learn.

```
kubectl exec -it cqlsh -- DROP TABLE IF EXISTS portworx.features
```{{execute T1}}

Ok, so we deleted our database, what now? Restore your snapshot and cary on.

### Step: Restore the snapshot and see your data is still there

First let's open a shell in one of our Portworx containers:
```
PX_POD=$(kubectl get pods -l name=portworx -n kube-system -o jsonpath='{.items[0].metadata.name}')
kubectl exec -it $PX_POD bash
```{{execute T1}}

Then iterate through the group snapshot volumes and first delete the original volume before cloning the snapshot using the same name.
```
for pvc in `pxctl v l | grep group | awk '{print $2}'`; do pxctl v d ${pvc:24:100} -f; pxctl v clone --name ${pvc:24:100} $pvc; done
exit
```{{execute T1}}

Now we can scale our cluster back up:
```
kubectl scale --replicas=3 sts cassandra
```{{execute T1}}

Watch to see the cassandra pods come back with the restored volumes.
```
watch kubectl get pods
```{{execute T1}}

When the pod is in Running state then then hit ```clear```{{execute interrupt}} to ctrl-c and clear the screen.
